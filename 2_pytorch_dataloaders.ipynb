{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a39e58",
   "metadata": {},
   "source": [
    "## PyTorch Dataloaders\n",
    "\n",
    "[Code](https://github.com/priyammaz/PyTorch-Adventures/blob/main/PyTorch%20Basics/PyTorch%20DataLoaders/DataLoaders.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635de1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder  # Stream data from images stored in folders\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os  # Allows to access files\n",
    "from PIL import Image  # Allows us to Load Images\n",
    "from collections import Counter  # Utility function to give us the counts of unique items in an iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812dc26a",
   "metadata": {},
   "source": [
    "## Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a43c2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 0.8447,  0.8618,  0.8447,  ...,  1.3755,  1.3584,  1.3070],\n",
      "         [ 0.9303,  0.9132,  0.8789,  ...,  1.3755,  1.3584,  1.3413],\n",
      "         [ 0.9988,  0.9474,  0.8618,  ...,  1.3242,  1.3413,  1.3242],\n",
      "         ...,\n",
      "         [ 0.1083,  0.4508,  0.4337,  ..., -0.7993, -1.0562, -1.0219],\n",
      "         [ 0.3138,  0.4679,  0.5193,  ..., -0.7650, -0.9877, -0.9877],\n",
      "         [ 0.0056,  0.1426,  0.1426,  ..., -0.7137, -0.9534, -0.9534]],\n",
      "\n",
      "        [[ 0.0651,  0.1001,  0.1001,  ...,  1.0105,  0.9930,  0.9405],\n",
      "         [ 0.1527,  0.1702,  0.1352,  ...,  1.0105,  0.9930,  0.9755],\n",
      "         [ 0.2577,  0.2227,  0.1527,  ...,  0.9580,  0.9755,  0.9580],\n",
      "         ...,\n",
      "         [ 1.0455,  1.4657,  1.4832,  ..., -0.8627, -1.1253, -1.1078],\n",
      "         [ 1.1155,  1.2381,  1.2731,  ..., -0.8452, -1.1078, -1.1253],\n",
      "         [ 0.7304,  0.8179,  0.7829,  ..., -0.7927, -1.0903, -1.1078]],\n",
      "\n",
      "        [[-0.1487, -0.0964, -0.0964,  ...,  0.5834,  0.5485,  0.4962],\n",
      "         [-0.0615, -0.0267, -0.0615,  ...,  0.5834,  0.5485,  0.5311],\n",
      "         [ 0.0256,  0.0256, -0.0615,  ...,  0.5311,  0.5311,  0.5136],\n",
      "         ...,\n",
      "         [ 1.7511,  2.2217,  2.2740,  ..., -0.7238, -1.0376, -1.0376],\n",
      "         [ 1.8208,  1.9428,  1.9603,  ..., -0.6367, -0.9330, -0.9853],\n",
      "         [ 1.4548,  1.5071,  1.4200,  ..., -0.5670, -0.8807, -0.9330]]]), 1)\n"
     ]
    }
   ],
   "source": [
    "class DogsVsCats(Dataset):\n",
    "    def __init__(self, path_to_folder):\n",
    "        path_to_cats = os.path.join(path_to_folder, \"Cat\")\n",
    "        path_to_dogs = os.path.join(path_to_folder, \"Dog\")\n",
    "\n",
    "        cat_files = os.listdir(path_to_cats)\n",
    "        dog_files = os.listdir(path_to_dogs)\n",
    "\n",
    "        path_to_cat_files = [os.path.join(path_to_cats, f) for f in cat_files]\n",
    "        path_to_dog_files = [os.path.join(path_to_dogs, f) for f in dog_files]\n",
    "\n",
    "        self.training_files = path_to_cat_files + path_to_dog_files\n",
    "\n",
    "        self.dog_label = 0\n",
    "        self.cat_label = 1\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize([224, 224]),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.training_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_to_image = self.training_files[index]\n",
    "\n",
    "        if \"Dog\" in path_to_image:\n",
    "            label = self.dog_label\n",
    "        else:\n",
    "            label = self.cat_label\n",
    "\n",
    "        image = Image.open(path_to_image).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "path_to_folder = \"./catsanddogs/PetImages/\"\n",
    "dataset = DogsVsCats(path_to_folder)\n",
    "\n",
    "for sample in dataset:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f7ab5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "dogs_vs_cats_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "for images, labels in dogs_vs_cats_loader:\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca9effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = int(0.9 * len(dataset))\n",
    "num_test_samples = len(dataset) - num_train_samples\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [num_train_samples, num_test_samples])\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "027d50aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cat', 'Dog']\n"
     ]
    }
   ],
   "source": [
    "dataset = ImageFolder(root=path_to_folder)\n",
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36803f2c",
   "metadata": {},
   "source": [
    "## NLP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c397e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [01:17<00:00, 324.66it/s]\n"
     ]
    }
   ],
   "source": [
    "path_to_data = \"./aclImdb/train\"\n",
    "\n",
    "path_to_pos_folder = os.path.join(path_to_data, \"pos\")\n",
    "path_to_neg_folder = os.path.join(path_to_data, \"neg\")\n",
    "\n",
    "path_to_pos_txt = [os.path.join(path_to_pos_folder, file) for file in os.listdir(path_to_pos_folder)]\n",
    "path_to_neg_txt = [os.path.join(path_to_neg_folder, file) for file in os.listdir(path_to_neg_folder)]\n",
    "\n",
    "training_files = path_to_pos_txt + path_to_neg_txt\n",
    "\n",
    "all_text = \"\"\n",
    "\n",
    "for file in tqdm(training_files):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.readlines()[0]\n",
    "        all_text += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "503d6824",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = dict(Counter(all_text))\n",
    "characters = sorted([key for key, value in unique_counts.items() if value > 1500])\n",
    "characters.append(\"<unk>\")\n",
    "characters.append(\"<pad>\")\n",
    "\n",
    "character_to_index = {character: index for index, character in enumerate(characters)}\n",
    "index_to_character = {index: character for index, character in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1551d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, path_to_data):\n",
    "        path_to_pos_folder = os.path.join(path_to_data, \"pos\")\n",
    "        path_to_neg_folder = os.path.join(path_to_data, \"neg\")\n",
    "\n",
    "        path_to_pos_txt = [os.path.join(path_to_pos_folder, file) for file in os.listdir(path_to_pos_folder)]\n",
    "        path_to_neg_txt = [os.path.join(path_to_neg_folder, file) for file in os.listdir(path_to_neg_folder)]\n",
    "\n",
    "        self.training_files = path_to_pos_txt + path_to_neg_txt\n",
    "        self.tokenizer = character_to_index\n",
    "\n",
    "        self.pos_level = 1\n",
    "        self.neg_level = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.training_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path_to_text = self.training_files[idx]\n",
    "        with open(path_to_text, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.readlines()[0]\n",
    "\n",
    "        tokenized = []\n",
    "\n",
    "        for char in text:\n",
    "            if char in self.tokenizer.keys():\n",
    "                tokenized.append(self.tokenizer[char])\n",
    "            else:\n",
    "                tokenized.append(self.tokenizer[\"<unk>\"])\n",
    "\n",
    "        sample = torch.tensor(tokenized)\n",
    "        label = self.pos_level if \"pos\" in path_to_text else self.neg_level\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b205580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284 1\n"
     ]
    }
   ],
   "source": [
    "path_to_data = \"./aclImdb/train\"\n",
    "dataset = IMDBDataset(path_to_data)\n",
    "\n",
    "for sample, label in dataset:\n",
    "    print(len(sample), label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c02c0",
   "metadata": {},
   "source": [
    "## Dynamic Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4d52b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.],\n",
      "        [  1.,   1.,   1.,   1.,   1.,   1.,   1.,   1., 999., 999.],\n",
      "        [  1.,   1., 999., 999., 999., 999., 999., 999., 999., 999.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(10)\n",
    "b = torch.ones(8)\n",
    "c = torch.ones(2)\n",
    "\n",
    "padded = nn.utils.rnn.pad_sequence([a, b, c], padding_value=999, batch_first=True)\n",
    "print(padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "720c2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collator(batch):\n",
    "    texts, labels = [], []\n",
    "\n",
    "    for text, label in batch:\n",
    "        texts.append(text)\n",
    "        labels.append(label)\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "    texts = nn.utils.rnn.pad_sequence(texts, batch_first=True, padding_value=character_to_index[\"<pad>\"])\n",
    "\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7b13602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32, 65, 68,  ..., 79, 79, 79],\n",
      "        [28, 59, 76,  ..., 79, 79, 79],\n",
      "        [27,  0, 69,  ..., 79, 79, 79],\n",
      "        [35, 70,  4,  ..., 55, 69, 10]])\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(dataset, batch_size=4, collate_fn=data_collator)\n",
    "\n",
    "for texts, labels in loader:\n",
    "    print(texts)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
