{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1e9b90",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "\n",
    "[Code](https://github.com/priyammaz/PyTorch-Adventures/blob/main/PyTorch%20for%20Computer%20Vision/ResNet/ResNet.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f06a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dde76f",
   "metadata": {},
   "source": [
    "## Increase number of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b8d3157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 32, 32])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(4, 16, 32, 32)\n",
    "conv = nn.Conv2d(in_channels=16, out_channels=256, kernel_size=1)\n",
    "conv(rand).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72050a1a",
   "metadata": {},
   "source": [
    "## Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614ef683",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, downsample=None, middle_conv_stride=1, residual=True):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        ### Set Convolutional Layers ###\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=middle_conv_stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        ### Output to planes * 4 as our expansion ###\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ### This Will Exist if a Downsample Is Needed ###\n",
    "        self.downsample = downsample\n",
    "        self.residual = residual\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if self.residual:\n",
    "            if self.downsample is not None:  # If our identity function has less channels or larger size we remap it\n",
    "                identity = self.downsample(identity)\n",
    "\n",
    "            x = x + identity\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc44cb",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2708f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, layer_counts, num_channels=3, num_classes=2, residual=True):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.residual = residual\n",
    "\n",
    "        self.in_planes = 64  # Starting number of planes to map to from input channels\n",
    "\n",
    "        ### INITIAL SET OF CONVOLUTIONS ###\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.in_planes, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_planes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        ### DEFINE LAYERS ###\n",
    "        self.layer1 = self._make_layers(layer_counts[0], 64, stride=1)\n",
    "        self.layer2 = self._make_layers(layer_counts[1], 128, stride=2)\n",
    "        self.layer3 = self._make_layers(layer_counts[2], 256, stride=2)\n",
    "        self.layer4 = self._make_layers(layer_counts[3], 512, stride=2)\n",
    "\n",
    "        ### AVERAGE POOLING AND MAP TO CLASSIFIER ###\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "    def _make_layers(self, num_residual_blocks, planes, stride=1):\n",
    "        downsample = None\n",
    "\n",
    "        # If we have a stride of 2, or the number of planes dont match. This condition will ALWAYS BE MET only\n",
    "        # on the first block of every set of blocks\n",
    "        if self.residual and (stride != 1 or self.in_planes != planes * 4):\n",
    "            ### Map to the number of wanted planes with a stride of 2 to map identity to X\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes * 4, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes * 4),\n",
    "            )\n",
    "\n",
    "        layers = nn.ModuleList()\n",
    "\n",
    "        ### Append this First Block with the Downsample Layer ###\n",
    "        layers.append(ResidualBlock(self.in_planes, planes, downsample, stride, residual=self.residual))\n",
    "\n",
    "        ### Set our InPlanes to be expanded by 4 ###\n",
    "        self.in_planes = planes * 4\n",
    "\n",
    "        ### The remaining layers shouldnt have any issues so we can just append all of teh blocks on ###\n",
    "        for _ in range(1, num_residual_blocks):\n",
    "            layers.append(ResidualBlock(self.in_planes, planes, residual=self.residual))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x).squeeze()\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def ResNet50(num_channels=3, num_classes=2, residual=True):\n",
    "    return ResNet([3, 4, 6, 3], num_channels, num_classes, residual)\n",
    "\n",
    "\n",
    "def ResNet101(num_channels=3, num_classes=2, residual=True):\n",
    "    return ResNet([3, 4, 23, 3], num_channels, num_classes, residual)\n",
    "\n",
    "\n",
    "def ResNet152(num_channels=3, num_classes=2, residual=True):\n",
    "    return ResNet([3, 8, 36, 3], num_channels, num_classes, residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6e84458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet50(residual=True)\n",
    "rand = torch.randn(4, 3, 224, 224)\n",
    "model(rand).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf9596",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a327747",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"mps:0\"\n",
    "path_to_data = \"./catsanddogs/PetImages/\"\n",
    "\n",
    "normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalizer,\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = ImageFolder(path_to_data, transform=train_transform)\n",
    "\n",
    "train_samples, test_samples = int(0.9 * len(dataset)), len(dataset) - int(0.9 * len(dataset))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, lengths=[train_samples, test_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c55265",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ffea945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, optimizer, loss_fn, train_loader, val_loader):\n",
    "    log_training = {\n",
    "        \"epoch\": [],\n",
    "        \"training_loss\": [],\n",
    "        \"validation_loss\": [],\n",
    "        \"training_acc\": [],\n",
    "        \"validation_acc\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        train_losses, train_accuracies = [], []\n",
    "        val_losses, val_accuracies = [], []\n",
    "\n",
    "        model.train()\n",
    "        for image, label in tqdm(train_loader, desc=\"Training\"):\n",
    "            image, label = image.to(DEVICE), label.to(DEVICE)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = loss_fn(output, label)\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            # Compute accuracy\n",
    "            predictions = torch.argmax(output, axis=-1)\n",
    "            accuracy = (predictions == label).float().mean()\n",
    "            train_accuracies.append(accuracy.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        for image, label in tqdm(val_loader, desc=\"Validation\"):\n",
    "            image, label = image.to(DEVICE), label.to(DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "                loss = loss_fn(output, label)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                # Compute accuracy\n",
    "                predictions = torch.argmax(output, axis=-1)\n",
    "                accuracy = (predictions == label).float().mean()\n",
    "                val_accuracies.append(accuracy.item())\n",
    "\n",
    "        training_loss_mean, training_acc_mean = np.mean(train_losses), np.mean(train_accuracies)\n",
    "        valid_loss_mean, valid_acc_mean = np.mean(val_losses), np.mean(val_accuracies)\n",
    "\n",
    "        log_training[\"epoch\"].append(epoch)\n",
    "        log_training[\"training_loss\"].append(training_loss_mean)\n",
    "        log_training[\"training_acc\"].append(training_acc_mean)\n",
    "        log_training[\"validation_loss\"].append(valid_loss_mean)\n",
    "        log_training[\"validation_acc\"].append(valid_acc_mean)\n",
    "\n",
    "        print(\"Training Loss:\", training_loss_mean)\n",
    "        print(\"Training Acc:\", training_acc_mean)\n",
    "        print(\"Validation Loss:\", valid_loss_mean)\n",
    "        print(\"Validation Acc:\", valid_acc_mean)\n",
    "\n",
    "    return log_training, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9975325c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training With Residuals\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5802b43d554418e87e3db11109e0a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafi/.local/share/mise/installs/python/3.12.9/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea1fc1949fe4f9dbc6aec2882a3d8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7387173284183849\n",
      "Training Acc: 0.624022531577132\n",
      "Validation Loss: 0.7154939323663712\n",
      "Validation Acc: 0.6644071698188782\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f00025c91f1408d907b80e72bfbcd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba7aa31e2994f4fb6e71cb6204ccf67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6199253963475878\n",
      "Training Acc: 0.6853439530188387\n",
      "Validation Loss: 0.6694673418998718\n",
      "Validation Acc: 0.6532169103622436\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561355f13a444296ad9e1f680775f4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f6c92f04b14983bc3ea02605c077d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.562695267864249\n",
      "Training Acc: 0.7353805513544516\n",
      "Validation Loss: 0.5274455919861794\n",
      "Validation Acc: 0.7406709551811218\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebe206921a44e358ce3beb40d2b14dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87020fc00f444fe68c2344957baa1b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4943343663418835\n",
      "Training Acc: 0.7685084864497185\n",
      "Validation Loss: 0.5168028131127358\n",
      "Validation Acc: 0.7470358461141586\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed86f38d1310495a96f3273c4e7e815b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e52f914ef2f41e18f6b3606579a9239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4493111680177125\n",
      "Training Acc: 0.7973406338556246\n",
      "Validation Loss: 0.5245400756597519\n",
      "Validation Acc: 0.7383731603622437\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1513a5e6654b4f6f907b9000d74f2720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22b301ac8fb4d54b11e32b4d81997a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3953708369623531\n",
      "Training Acc: 0.8257461010732434\n",
      "Validation Loss: 0.43145697116851806\n",
      "Validation Acc: 0.8218520224094391\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d185927dbee44eda9f69558797bdbcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6991bc1bffa4a61934399e66459e7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.33817565508864145\n",
      "Training Acc: 0.8554288904097948\n",
      "Validation Loss: 0.334450426697731\n",
      "Validation Acc: 0.8668658077716828\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cba9335bc6b4c9bb719d6f8f44fa47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fee473a4db3455b905f8dba5ad2be41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.29454651864414866\n",
      "Training Acc: 0.8746829341081056\n",
      "Validation Loss: 0.3160972461104393\n",
      "Validation Acc: 0.8654411762952805\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b73ecb32da488cb57a44074d312b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142b5379c1a449a092788d2aa7d76e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2593655598942529\n",
      "Training Acc: 0.890116788785566\n",
      "Validation Loss: 0.27659997940063474\n",
      "Validation Acc: 0.8780101090669632\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde560eef52043c59ff67ee5e3a3f8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a037a5a9d643a1b40f25dc26a620d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.22801451029425318\n",
      "Training Acc: 0.9031264494088563\n",
      "Validation Loss: 0.40838886350393294\n",
      "Validation Acc: 0.8550551474094391\n"
     ]
    }
   ],
   "source": [
    "print(\"Training With Residuals\")\n",
    "resnet_w_res, model = train(model, EPOCHS, optimizer, loss_fn, train_loader, val_loader)\n",
    "\n",
    "model = model.to(\"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
